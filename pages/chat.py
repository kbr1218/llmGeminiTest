# chat.py
import streamlit as st
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_community.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate
from langchain_teddynote import logging

from dotenv import load_dotenv
import os

# ì±—ë´‡ ì´ë¯¸ì§€ ë§í¬ ì„ ì–¸
botImgPath = 'https://raw.githubusercontent.com/kbr1218/streamlitTest/main/imgs/dolhareubang3.png'

# í˜ì´ì§€ ì œëª© ì„¤ì •
st.set_page_config(page_title="chat", page_icon="ğŸ’¬", layout="wide",
                   initial_sidebar_state='expanded')

from pages.subpages import sidebar, chat_search

# ì‚¬ì´ë“œë°”
with st.sidebar:
    sidebar.show_sidebar()


##########################
### 00. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ###
load_dotenv()
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
# langsmith ì¶”ì  ì„¤ì •
logging.langsmith("bigcon_langchain_test")


### 1. HuggingFace ì„ë² ë”© ìƒì„± ###
embeddings  = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")


## 2. Chroma ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ###
vectorstore = Chroma(persist_directory="./database_all_with_meta", embedding_function=embeddings)


## 3. ì‚¬ìš©ì ì •ë³´ ê¸°ë°˜ ì§€ì—­ í•„í„°ë§ ###
user_name = st.session_state.get('user_name', [])
user_age = st.session_state.get('age', [])
visit_dates = st.session_state.get('visit_dates', [])
visit_times = st.session_state.get('visit_times', [])
visit_region = st.session_state.get('region', [])

# í•„í„° ì¡°ê±´ êµ¬ì„±
region_filter = {"ì§€ì—­": {"$in": visit_region}}
print(f"í•„í„°ë§ëœ ì§€ì—­: {visit_region}")
print(f"í•„í„° ì¡°ê±´: {region_filter}")


## 4. ê²€ìƒ‰ê¸° ìƒì„± ###
retriever = vectorstore.as_retriever(
    search_type="mmr",   
    search_kwargs={"k": 10,
                   "fetch_k": 10,
                   "filters": region_filter}
)


## 5. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì • (ìˆ˜ì • í•„ìš”: ë‚ ì”¨ì— ê¸°ë°˜í•˜ì—¬ ëŒ€ë‹µí•˜ë„ë¡ ìˆ˜ì •) ###
template = """
[context]: {context}
---
[ì§ˆì˜]: {query}
---
[ëŒ€ë‹µ ì˜ˆì‹œ]
ì œì£¼ë„ ë¶ë¶€ì—ì„œ 30ëŒ€ ì—¬ì„±ì´ ì¢‹ì•„í•˜ëŠ” ê°€ì •ì‹ ë§›ì§‘ì„ ì¶”ì²œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤!
ì œì£¼ë„ë¥¼ ë°©ë¬¸í•˜ì‹¤ ë‚ ì§œëŠ” {visit_dates} ì´ê³ , {visit_times} ì‹œê°„ëŒ€ì— ë°©ë¬¸í•˜ì‹¤ ê³„íšì´êµ°ìš”.
2023ë…„ ì œì£¼ë„ ë¶ë¶€ì˜ {visit_dates}ì›” {visit_times}ì˜ í‰ê·  ê¸°ì˜¨ì€ xx.xÂ°ì˜€ìŠµë‹ˆë‹¤. # ì‹œê°„ë³„ ê¸°ì˜¨ ë°ì´í„° ì°¸ê³   
ê°™ì€ ê¸°ì˜¨ì„ ê°€ì§„ ë‚ , {visit_times}ì— {visit_region}ì—ì„œ 30ëŒ€ ì—¬ì„± ë°©ë¬¸ ë¹„ì¤‘ì´ ë†’ì•˜ë˜ ê°€ì •ì‹ ë§›ì§‘ì„ ì¶”ì²œë“œë¦¬ê² ìŠµë‹ˆë‹¤.
1. **(ê°€ë§¹ì ëª…)**: {context} #ë¬¸ì„œì— ìˆëŠ” ê¸°ì˜¨ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ìœ  ì„¤ëª…
----
[ì¶”ê°€ ì •ë³´]
ë‹¹ì‹ ì€ ì£¼ì–´ì§„ [context]ì™€ ì‚¬ìš©ìê°€ ì„ íƒí•œ ì§€ì—­ ì¡°ê±´ì— ë§ê²Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
you must answer based on {visit_dates} monthly, {visit_times} hourly temperature data. 
ë‹¹ì‹ ì€ ë°˜ë“œì‹œ ì£¼ì–´ì§„ ê¸°ì˜¨ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤. ì‹œê°„ë³„ í‰ê·  ê¸°ì˜¨ ë°ì´í„°ë¥¼ ë°˜ë“œì‹œ ì°¸ê³ í•˜ì„¸ìš”.
visit_dates ë³€ìˆ˜ì™€ visit_region ë³€ìˆ˜, visit_times ë³€ìˆ˜ ë¬¸ì„œì— ë”°ë¼ ë§ì¶¤í˜• ë§›ì§‘ì„ 2ê°œ ë˜ëŠ” 3ê°œ ì¶”ì²œí•˜ê³ , ì´ìœ ë¥¼ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.

[ë°ì´í„° ì„¤ëª…]
ê¸°ì¤€ë…„ì›”-2023ë…„ 1ì›”~12ì›”,
ì—…ì¢…-ìš”ì‹ê´€ë ¨ 30ê°œ ì—…ì¢…ìœ¼ë¡œ êµ¬ë¶„ (ì—…ì¢…ì´ 'ì»¤í”¼'ì¼ ê²½ìš° 'ì¹´í˜' ëœ»í•¨ ),
ì§€ì—­-ì œì£¼ë„ë¥¼ 10ê°œì˜ ì§€ì—­ìœ¼ë¡œ êµ¬ë¶„(ë™ë¶€/ì„œë¶€/ë‚¨ë¶€/ë¶ë¶€/ì‚°ì§€/ê°€íŒŒë„/ë§ˆë¼ë„/ë¹„ì–‘ë„/ìš°ë„/ì¶”ìë„),
ì£¼ì†Œ-ê°€ë§¹ì  ì£¼ì†Œ,
ì›”ë³„_ì—…ì¢…ë³„_ì´ìš©ê±´ìˆ˜_ìˆœìœ„-ì›”ë³„ ì—…ì¢…ë³„ ì´ìš©ê±´ìˆ˜ ë¶„ìœ„ìˆ˜ êµ¬ê°„ì„ 6ê°œ êµ¬ê°„ìœ¼ë¡œ ì§‘ê³„ ì‹œ í•´ë‹¹ ê°€ë§¹ì ì˜ ì´ìš©ê±´ìˆ˜ê°€ í¬í•¨ë˜ëŠ” ë¶„ìœ„ìˆ˜ êµ¬ê°„ * 1:ìƒìœ„10%ì´í•˜ 2:ìƒìœ„10~25% 3:ìƒìœ„25~50% 4:ìƒìœ„50~75% 5:ìƒìœ„75~90% 6:ìƒìœ„90% ì´ˆê³¼(í•˜ìœ„10%ì´í•˜) * ìƒìœ„ 30% ë§¤ì¶œ ê°€ë§¹ì  ë‚´ ë¶„ìœ„ìˆ˜ êµ¬ê°„ì„,
ì›”ë³„_ì—…ì¢…ë³„_ì´ìš©ê¸ˆì•¡_ìˆœìœ„-ì›”ë³„ ì—…ì¢…ë³„ ì´ìš©ê¸ˆì•¡ ë¶„ìœ„ìˆ˜ êµ¬ê°„ì„ 6ê°œ êµ¬ê°„ìœ¼ë¡œ ì§‘ê³„ ì‹œ í•´ë‹¹ ê°€ë§¹ì ì˜ ì´ìš©ê¸ˆì•¡ì´ í¬í•¨ë˜ëŠ” ë¶„ìœ„ìˆ˜ êµ¬ê°„ * 1:ìƒìœ„10%ì´í•˜ 2:ìƒìœ„10~25% 3:ìƒìœ„25~50% 4:ìƒìœ„50~75% 5:ìƒìœ„75~90% 6:ìƒìœ„90% ì´ˆê³¼(í•˜ìœ„10%ì´í•˜) * ìƒìœ„ 30% ë§¤ì¶œ ê°€ë§¹ì  ë‚´ ë¶„ìœ„ìˆ˜ êµ¬ê°„ì„,
ê±´ë‹¹_í‰ê· _ì´ìš©ê¸ˆì•¡_ìˆœìœ„-ì›”ë³„ ì—…ì¢…ë³„ ê±´ë‹¹í‰ê· ì´ìš©ê¸ˆì•¡ ë¶„ìœ„ìˆ˜ êµ¬ê°„ì„ 6ê°œ êµ¬ê°„ìœ¼ë¡œ ì§‘ê³„ ì‹œ í•´ë‹¹ ê°€ë§¹ì ì˜ ê±´ë‹¹í‰ê· ì´ìš©ê¸ˆì•¡ì´ í¬í•¨ë˜ëŠ” ë¶„ìœ„ìˆ˜ êµ¬ê°„ * 1:ìƒìœ„10%ì´í•˜ 2:ìƒìœ„10~25% 3:ìƒìœ„25~50% 4:ìƒìœ„50~75% 5:ìƒìœ„75~90% 6:ìƒìœ„90% ì´ˆê³¼(í•˜ìœ„10%ì´í•˜) * ìƒìœ„ 30% ë§¤ì¶œ ê°€ë§¹ì  ë‚´ ë¶„ìœ„ìˆ˜ êµ¬ê°„ì„,
í˜„ì§€ì¸_ì´ìš©_ê±´ìˆ˜_ë¹„ì¤‘-ê³ ê° ìíƒ ì£¼ì†Œê°€ ì œì£¼ë„ì¸ ê²½ìš°ë¥¼ í˜„ì§€ì¸ìœ¼ë¡œ ì •ì˜
"""
prompt = ChatPromptTemplate.from_template(template)


### 6. Google Gemini ëª¨ë¸ ìƒì„± ###
@st.cache_resource
def load_model():
    system_instruction = (
        "ë‹¹ì‹ ì€ ì œì£¼ë„ ì—¬í–‰ê°ì—ê²Œ ì œì£¼ë„ ë§›ì§‘ì„ ì¶”ì²œí•˜ëŠ” 'ì¹œì ˆí•œ ì œì£¼Â°C' ì±—ë´‡ì…ë‹ˆë‹¤. "
        "ê±°ì§“ë§ì„ í•  ìˆ˜ ì—†ìœ¼ë©°, ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–˜ê¸°í•˜ì„¸ìš”."
    )
    model = ChatGoogleGenerativeAI(
        model="gemini-1.5-flash",
        temperature=0,
        max_tokens=5000,
        system_instruction=system_instruction
    )
    print("model loaded...")
    return model
model = load_model()



### 7. ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© í•¨ìˆ˜ ###
def merge_pages(pages):
    merged = "\n\n".join(page.page_content for page in pages)
    return merged


## 8. LangChain ì²´ì¸ êµ¬ì„± ###
chain = (
    {"query": RunnablePassthrough(),
     "context": retriever | merge_pages,      # retrieverë¡œ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ merge_pages í•¨ìˆ˜ì— ì „ë‹¬
     "visit_dates":RunnablePassthrough(),
     "visit_times":RunnablePassthrough(),
     "visit_region":RunnablePassthrough(),
     "user_age":RunnablePassthrough(),
     "user_name":RunnablePassthrough()
    }
    | prompt
    | load_model()
    | StrOutputParser()
)


### 9. Streamlit UI ###
st.subheader("ğŸŠ:orange[ì œì£¼Â°C]ì—ê²Œ ì§ˆë¬¸í•˜ê¸°")
st.divider()

user_input = st.chat_input(
    placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: ì¶”ìë„ì— ìˆëŠ” ê°€ì •ì‹ ë§›ì§‘ì„ ì¶”ì²œí•´ì¤˜)",
    max_chars=150
)

chat_col1, search_col2 = st.columns([2, 1])
with chat_col1:
    if 'messages' not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": """ì•ˆë…•í•˜ì„¸ìš”!  
            ì œì£¼ë„ì˜ ì§€ì—­/ì‹œê°„ë³„ ê¸°ì˜¨ ë°ì´í„°ì— ê¸°ë°˜í•˜ì—¬ ë§›ì§‘ì„ ì¶”ì²œí•˜ëŠ” :orange[**ì¹œì ˆí•œ ì œì£¼Â°C**]ì…ë‹ˆë‹¤.  
            ì–¸ì œë“ ì§€ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."""}
        ]

    for message in st.session_state.messages:
        avatar = "ğŸ§‘ğŸ»" if message['role'] == 'user' else botImgPath
        with st.chat_message(message['role'], avatar=avatar):
            st.markdown(message['content'])

    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user", avatar="ğŸ§‘ğŸ»"):
            st.markdown(user_input)

        # ì¶”ì²œ ìƒì„± ì¤‘ ìŠ¤í”¼ë„ˆ
        with st.spinner("ë§›ì§‘ ì°¾ëŠ” ì¤‘..."):
            # chain.invokeì—ì„œ ê°œë³„ ë³€ìˆ˜ë¡œ ì „ë‹¬
            assistant_response = chain.invoke(user_input)

        # Assistant ì‘ë‹µ ê¸°ë¡ì— ì¶”ê°€ ë° ì¶œë ¥
        st.session_state.messages.append({"role": "assistant", "content": assistant_response})
        with st.chat_message("assistant", avatar=botImgPath):
            st.markdown(assistant_response)

with search_col2:
    chat_search.show_search_restaurant()