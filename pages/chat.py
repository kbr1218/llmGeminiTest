# chat.py
import streamlit as st
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_community.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate
from langchain_teddynote import logging

from dotenv import load_dotenv
import os

# ì±—ë´‡ ì´ë¯¸ì§€ ë§í¬ ì„ ì–¸
botImgPath = 'https://raw.githubusercontent.com/kbr1218/streamlitTest/main/imgs/dolhareubang3.png'

# í˜ì´ì§€ ì œëª© ì„¤ì •
st.set_page_config(page_title="chat", page_icon="ğŸ’¬", layout="wide",
                   initial_sidebar_state='expanded')

from pages.subpages import sidebar, chat_search

# ì‚¬ì´ë“œë°”
with st.sidebar:
    sidebar.show_sidebar()


##########################
### 00. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ###
load_dotenv()
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
# langsmith ì¶”ì  ì„¤ì •
logging.langsmith("bigcon_langchain_test")


### 1. HuggingFace ì„ë² ë”© ìƒì„± ###
embeddings  = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")


## 2. Chroma ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ###
vectorstore = Chroma(persist_directory="./database_all_with_meta", embedding_function=embeddings)


## 3. ì‚¬ìš©ì ì •ë³´ ê¸°ë°˜ ì§€ì—­ í•„í„°ë§ ###
user_name = st.session_state.get('user_name', [])
user_age = st.session_state.get('age', [])
visit_dates = st.session_state.get('visit_dates', [])
visit_times = st.session_state.get('visit_times', [])
visit_region = st.session_state.get('region', [])

# í•„í„° ì¡°ê±´ êµ¬ì„±
region_filter = {"ì§€ì—­": {"$in": visit_region}}
print(f"í•„í„°ë§ëœ ì§€ì—­: {visit_region}")
print(f"í•„í„° ì¡°ê±´: {region_filter}")


## 4. ê²€ìƒ‰ê¸° ìƒì„± ###
retriever = vectorstore.as_retriever(
    search_type="mmr",   
    search_kwargs={"k": 10,
                   "fetch_k": 10,
                   "filters": region_filter}
)


## 5. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì • (ìˆ˜ì • í•„ìš”: ë‚ ì”¨ì— ê¸°ë°˜í•˜ì—¬ ëŒ€ë‹µí•˜ë„ë¡ ìˆ˜ì •) ###
template = """
[context]: {context}
---
[ì§ˆì˜]: {query}
---
[ì˜ˆì‹œ ì‘ë‹µ]
{visit_dates}ì— {visit_region} ì§€ì—­ ë°©ë¬¸ì„ ê³„íší•˜ì‹  {user_age}ì—ê²Œ {visit_times}ì— ë°©ë¬¸í•˜ê¸° ì¢‹ì€ ë§›ì§‘ì„ ì¶”ì²œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤!
ì¶”ì²œ ê¸°ì¤€:
 - ê¸°ì˜¨: {visit_dates}ì›” {visit_times}ì— í‰ê·  ê¸°ì˜¨ê³¼ ìœ ì‚¬í•œ ì‹œê°€ì— ë°©ë¬¸ê°ì´ ë§ì•˜ë˜ ë§›ì§‘ì„ ìš°ì„  ê³ ë ¤í–ˆìŠµë‹ˆë‹¤.
 - ì‹œê°„ëŒ€: {visit_times} ì´ìš© ê±´ìˆ˜ ë¹„ì¤‘ì´ ë†’ì€ ê°€ë§¹ì ì„ ìš°ì„  ê³ ë ¤í–ˆìŠµë‹ˆë‹¤.  

ì¶”ì²œ ë§›ì§‘:
- **ê°€ë§¹ì ëª…**: {visit_dates}ì›”ì˜ í‰ê·  ê¸°ì˜¨ì€ xx.xxÂ°ì´ê³ , íŠ¹íˆ, {visit_times}ì˜ í‰ê·  ê¸°ì˜¨ì€ xx.xxÂ°ì…ë‹ˆë‹¤. {visit_times}ì˜ ì´ìš© ê±´ìˆ˜ ë¹„ì¤‘ì´ xx.xx%ë¡œ ë†’ìŠµë‹ˆë‹¤. ì›”ë³„/ì—…ì¢…ë³„ ì´ìš© ê±´ìˆ˜ ìˆœìœ„ë„ xìœ„ë¡œ ë†’ì€ í¸ì…ë‹ˆë‹¤.

----
[ì¶”ê°€ ì •ë³´]
ë‹¹ì‹ ì€ ì£¼ì–´ì§„ [context]ì— ë§ê²Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤. If you can't find data, say you don't know.
you must fill "xx.xx" in example answer based on {visit_dates}, {visit_times} average temperature data or ì›”ë³„_ì—…ì¢…ë³„_ì´ìš©ê±´ìˆ˜_ìˆœìœ„, ì‹œê°„ë³„ ì´ìš©ê±´ìˆ˜_ë¹„ì¤‘ data.
{visit_dates}ì™€ {visit_region}, {visit_times}ì— ë”°ë¼ ë§ì¶¤í˜• ë§›ì§‘ì„ 2ê°œ ë˜ëŠ” 3ê°œ ì¶”ì²œí•˜ê³ , ì´ìœ ë¥¼ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”, ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í•œë‹¤ë©´ í†µê³„ë¥¼ ìƒëµí•´ë„ ì¢‹ìŠµë‹ˆë‹¤.
ì¶”ì²œ ê¸°ì¤€ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
- ê¸°ì˜¨: ì œê³µëœ ì›”ë³„&ì‹œê°„ë³„ í‰ê·  ê¸°ì˜¨ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¹„ìŠ·í•œ ê¸°ì˜¨ì˜ ë‚ ì— ë°©ë¬¸ê°ì´ ë§ì•˜ë˜ ê°€ë§¹ì ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.
- ì‹œê°„ëŒ€: ì‹œê°„ëŒ€ë³„ ì´ìš© ê±´ìˆ˜ ë¹„ì¤‘ì´ ë†’ì€ ê°€ë§¹ì ì„ ìš°ì„  ì¶”ì²œí•©ë‹ˆë‹¤.

[ë°ì´í„° ì„¤ëª…]
{user_age}: ì‚¬ìš©ìì˜ ì—°ë ¹ëŒ€,
{visit_dates}: ì‚¬ìš©ìê°€ ì œì£¼ë„ë¥¼ ë°©ë¬¸í•˜ëŠ” ê¸°ê°„,
{visit_times}: ì‚¬ìš©ìê°€ ë§›ì§‘ì„ ë°©ë¬¸í•  ì‹œê°„,
{visit_region}: ì‚¬ìš©ìê°€ ë°©ë¬¸í•˜ëŠ” ì œì£¼ë„ ì§€ì—­,
ê¸°ì¤€ë…„ì›”-2023ë…„ 1ì›”~12ì›”,
ì—…ì¢…-ìš”ì‹ê´€ë ¨ 30ê°œ ì—…ì¢…ìœ¼ë¡œ êµ¬ë¶„ (ì—…ì¢…ì´ 'ì»¤í”¼'ì¼ ê²½ìš° 'ì¹´í˜' ëœ»í•¨ ),
ì§€ì—­-ì œì£¼ë„ë¥¼ 10ê°œì˜ ì§€ì—­ìœ¼ë¡œ êµ¬ë¶„(ë™ë¶€/ì„œë¶€/ë‚¨ë¶€/ë¶ë¶€/ì‚°ì§€/ê°€íŒŒë„/ë§ˆë¼ë„/ë¹„ì–‘ë„/ìš°ë„/ì¶”ìë„),
ì£¼ì†Œ-ê°€ë§¹ì  ì£¼ì†Œ,
ì›”ë³„_ì—…ì¢…ë³„_ì´ìš©ê±´ìˆ˜_ìˆœìœ„: ì›”ë³„ ì—…ì¢…ë³„ ì´ìš©ê±´ìˆ˜ ë¶„ìœ„ìˆ˜ êµ¬ê°„ì„ 6ê°œ êµ¬ê°„ìœ¼ë¡œ ì§‘ê³„ ì‹œ í•´ë‹¹ ê°€ë§¹ì ì˜ ì´ìš©ê±´ìˆ˜ê°€ í¬í•¨ë˜ëŠ” ë¶„ìœ„ìˆ˜ êµ¬ê°„ * 1:ìƒìœ„ 10%ì´í•˜ 2:ìƒìœ„ 10~25% 3:ìƒìœ„ 25~50% 4:ìƒìœ„ 50~75% 5:ìƒìœ„ 75~90% 6:ìƒìœ„ 90% ì´ˆê³¼(í•˜ìœ„ 10%ì´í•˜),
ì›”ë³„_ì—…ì¢…ë³„_ì´ìš©ê¸ˆì•¡_ìˆœìœ„: ì›”ë³„ ì—…ì¢…ë³„ ì´ìš©ê¸ˆì•¡ ë¶„ìœ„ìˆ˜ êµ¬ê°„ì„ 6ê°œ êµ¬ê°„ìœ¼ë¡œ ì§‘ê³„ ì‹œ í•´ë‹¹ ê°€ë§¹ì ì˜ ì´ìš©ê¸ˆì•¡ì´ í¬í•¨ë˜ëŠ” ë¶„ìœ„ìˆ˜ êµ¬ê°„ * 1:ìƒìœ„ 10%ì´í•˜ 2:ìƒìœ„ 10~25% 3:ìƒìœ„ 25~50% 4:ìƒìœ„ 50~75% 5:ìƒìœ„ 75~90% 6:ìƒìœ„ 90% ì´ˆê³¼(í•˜ìœ„ 10%ì´í•˜),
ê±´ë‹¹_í‰ê· _ì´ìš©ê¸ˆì•¡_ìˆœìœ„: ì›”ë³„ ì—…ì¢…ë³„ ê±´ë‹¹í‰ê· ì´ìš©ê¸ˆì•¡ ë¶„ìœ„ìˆ˜ êµ¬ê°„ì„ 6ê°œ êµ¬ê°„ìœ¼ë¡œ ì§‘ê³„ ì‹œ í•´ë‹¹ ê°€ë§¹ì ì˜ ê±´ë‹¹ í‰ê·  ì´ìš©ê¸ˆì•¡ì´ í¬í•¨ë˜ëŠ” ë¶„ìœ„ìˆ˜ êµ¬ê°„ * 1:ìƒìœ„ 10%ì´í•˜ 2:ìƒìœ„ 10~25% 3:ìƒìœ„ 25~50% 4:ìƒìœ„ 50~75% 5:ìƒìœ„ 75~90% 6:ìƒìœ„ 90% ì´ˆê³¼(í•˜ìœ„ 10%ì´í•˜),
í˜„ì§€ì¸_ì´ìš©_ê±´ìˆ˜_ë¹„ì¤‘: ê³ ê° ìíƒ ì£¼ì†Œê°€ ì œì£¼ë„ì¸ ê²½ìš°ë¥¼ í˜„ì§€ì¸ìœ¼ë¡œ ì •ì˜
"""
prompt = ChatPromptTemplate.from_template(template)


### 6. Google Gemini ëª¨ë¸ ìƒì„± ###
# @st.cache_resource
def load_model():
    system_instruction = (
        "ë‹¹ì‹ ì€ ì œì£¼ë„ ì—¬í–‰ê°ì—ê²Œ ì œì£¼ë„ ë§›ì§‘ì„ ì¶”ì²œí•˜ëŠ” 'ì¹œì ˆí•œ ì œì£¼Â°C' ì±—ë´‡ì…ë‹ˆë‹¤. "
        "ì‚¬ìš©ìê°€ ì‚¬ì „ì— ì œê³µí•œ ë°ì´í„°({user_age}, {visit_dates}, {start_month}, {end_month}, {visit_times}, {visit_region})ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–˜ê¸°í•˜ì„¸ìš”."
    )
    model = ChatGoogleGenerativeAI(
        model="gemini-1.5-flash",
        temperature=0,
        max_tokens=5000,
        system_instruction=system_instruction
    )
    print("model loaded...")
    return model
model = load_model()



### 7. ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© í•¨ìˆ˜ ###
def merge_pages(pages):
    merged = "\n\n".join(page.page_content for page in pages)
    return merged


## 8. LangChain ì²´ì¸ êµ¬ì„± ###
chain = (
    {"query": RunnablePassthrough(),
     "context": retriever | merge_pages,      # retrieverë¡œ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ merge_pages í•¨ìˆ˜ì— ì „ë‹¬
     "visit_dates":RunnablePassthrough(),
     "visit_times":RunnablePassthrough(),
     "visit_region":RunnablePassthrough(),
     "user_age":RunnablePassthrough(),
     "user_name":RunnablePassthrough()
    }
    | prompt
    | load_model()
    | StrOutputParser()
)


### 9. Streamlit UI ###
st.subheader("ğŸŠ:orange[ì œì£¼Â°C]ì—ê²Œ ì§ˆë¬¸í•˜ê¸°")
st.divider()

user_input = st.chat_input(
    placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: ì¶”ìë„ì— ìˆëŠ” ê°€ì •ì‹ ë§›ì§‘ì„ ì¶”ì²œí•´ì¤˜)",
    max_chars=150
)

chat_col1, search_col2 = st.columns([2, 1])
with search_col2:
    chat_search.show_search_restaurant()

    # ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
    if st.button("ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”", type='primary'):
        st.session_state.messages = [
            {"role": "assistant", "content": """ì•ˆë…•í•˜ì„¸ìš”!  
            ì œì£¼ë„ì˜ ì§€ì—­/ì‹œê°„ë³„ ê¸°ì˜¨ ë°ì´í„°ì— ê¸°ë°˜í•˜ì—¬ ë§›ì§‘ì„ ì¶”ì²œí•˜ëŠ” :orange[**ì¹œì ˆí•œ ì œì£¼Â°C**]ì…ë‹ˆë‹¤.  
            ì–¸ì œë“ ì§€ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."""}
        ]
        st.rerun()

with chat_col1:
    if 'messages' not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": """ì•ˆë…•í•˜ì„¸ìš”!  
            ì œì£¼ë„ì˜ ì§€ì—­/ì‹œê°„ë³„ ê¸°ì˜¨ ë°ì´í„°ì— ê¸°ë°˜í•˜ì—¬ ë§›ì§‘ì„ ì¶”ì²œí•˜ëŠ” :orange[**ì¹œì ˆí•œ ì œì£¼Â°C**]ì…ë‹ˆë‹¤.  
            ì–¸ì œë“ ì§€ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."""}
        ]
    # í•„ìˆ˜ ì •ë³´ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥
    if not (user_age and visit_dates and visit_times and visit_region):
        st.error("ì‚¬ìš©ì ì •ë³´(ë‚˜ì´, ë°©ë¬¸ ë‚ ì§œ, ì‹œê°„, ì§€ì—­)ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        st.stop()  # ì´í›„ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì§€ ì•Šë„ë¡ ì¤‘ë‹¨


    for message in st.session_state.messages:
        avatar = "ğŸ§‘ğŸ»" if message['role'] == 'user' else botImgPath
        with st.chat_message(message['role'], avatar=avatar):
            st.markdown(message['content'])

    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user", avatar="ğŸ§‘ğŸ»"):
            st.markdown(user_input)

        # ì¶”ì²œ ìƒì„± ì¤‘ ìŠ¤í”¼ë„ˆ
        with st.spinner("ë§›ì§‘ ì°¾ëŠ” ì¤‘..."):
            # chain.invokeì—ì„œ ê°œë³„ ë³€ìˆ˜ë¡œ ì „ë‹¬
            assistant_response = chain.invoke(user_input+f"""
                                              user_name: {user_name},
                                              user_age: {user_age},
                                              visit_region: {visit_region},
                                              visit_dates: {visit_dates},
                                              visit_times: {visit_times},
                                              chat_history: {st.session_state.messages}
                                              """)

        # Assistant ì‘ë‹µ ê¸°ë¡ì— ì¶”ê°€ ë° ì¶œë ¥
        st.session_state.messages.append({"role": "assistant", "content": assistant_response})
        with st.chat_message("assistant", avatar=botImgPath):
            st.markdown(assistant_response)  
