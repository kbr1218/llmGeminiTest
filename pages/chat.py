# chat.py
import streamlit as st

from langchain_community.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings

from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain.prompts import ChatPromptTemplate

from langchain_teddynote import logging
from functions import load_model

# ì±—ë´‡ ì´ë¯¸ì§€ ë§í¬ ì„ ì–¸
botImgPath = 'https://raw.githubusercontent.com/kbr1218/streamlitTest/main/imgs/jejudoC.png'

# í˜ì´ì§€ ì œëª© ì„¤ì •
st.set_page_config(page_title="ì œì£¼Â°C", page_icon="ğŸ’¬", layout="wide",
                   initial_sidebar_state='expanded')

from pages.subpages import sidebar
from pages.subpages import chat_search

# ì‚¬ì´ë“œë°”
with st.sidebar:
    sidebar.show_sidebar()


##########################
### 00. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ###
# langsmith ì¶”ì  ì„¤ì •
# logging.langsmith("bigcon_langchain_test")


### 1. HuggingFace ì„ë² ë”© ìƒì„± ###
embeddings  = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")


## 2. Chroma ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ###
vectorstore = Chroma(persist_directory="./restaurant_vectorstore_ALL", embedding_function=embeddings)
temperature_vectorstore = Chroma(persist_directory="./temperature_vectorstore", embedding_function=embeddings)


## 3. ì‚¬ìš©ì ì •ë³´ ê¸°ë°˜ ì§€ì—­ í•„í„°ë§ ###
user_name = st.session_state.get('user_name', 'ì‚¬ìš©ì')
user_age = st.session_state.get('age', None)
visit_times = st.session_state.get('visit_times', None)
visit_region = st.session_state.get('region', [])
visit_dates = st.session_state.get('visit_dates', None)
# ì›” ì •ë³´ë§Œ ì¶œë ¥
visit_month = f"{visit_dates.month}ì›”" if visit_dates else ""

### 3-1. ì‚¬ìš©ì ë°ì´í„°ì™€ ì¼ì¹˜í•˜ëŠ” ì»¬ëŸ¼ëª… í…ìŠ¤íŠ¸ ìƒì„± ###
age_col = f'{user_age} íšŒì›ìˆ˜ ë¹„ì¤‘' if user_age else None
weekday_idx = visit_dates.weekday() if visit_dates else None
weekdays = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼']
weekdays_col = f'{weekdays[weekday_idx]} ì´ìš©ê±´ìˆ˜ ë¹„ì¤‘' if weekday_idx is not None else None
time_col = {
    "ì•„ì¹¨ (05-11ì‹œ)": "5ì‹œ-11ì‹œ ì´ìš©ê±´ìˆ˜ ë¹„ì¤‘",
    "ì ì‹¬ (12-13ì‹œ)": "12ì‹œ-13ì‹œ ì´ìš©ê±´ìˆ˜ ë¹„ì¤‘",
    "ì˜¤í›„ (14-17ì‹œ)": "14ì‹œ-17ì‹œ ì´ìš©ê±´ìˆ˜ ë¹„ì¤‘",
    "ì €ë… (18-22ì‹œ)": "18ì‹œ-22ì‹œ ì´ìš©ê±´ìˆ˜ ë¹„ì¤‘",
    "ì‹¬ì•¼ (23-04ì‹œ)": "23ì‹œ-4ì‹œ ì´ìš©ê±´ìˆ˜ ë¹„ì¤‘"
}.get(visit_times, None)

### 4. ê¸°ì˜¨ ë°ì´í„° ë¡œë“œ ###
temp_retriever = temperature_vectorstore.as_retriever(
    search_type="mmr",   
    search_kwargs={"k": 5}  # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë‹¤ì„¯ ê°œì˜ ë¬¸ì„œë§Œ ê°€ì ¸ì˜¤ê¸°
)

### 5. ê²€ìƒ‰ê¸° ìƒì„± ###
retriever = vectorstore.as_retriever(
    search_type="mmr",   
    search_kwargs={"k": 10,              # ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜ (default: 4)
                   "fetch_k": 50,        # MMR ì•Œê³ ë¦¬ì¦˜ì— ì „ë‹¬í•  ë¬¸ì„œ ìˆ˜
                   "lambda_mult": 0.5,    # ê²°ê³¼ ë‹¤ì–‘ì„± ì¡°ì ˆ (default: 0.5),
                   'filter': {'ì§€ì—­': {'$in':visit_region}}
                   }
)

### 6. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì • ###
template = """
You are an assistant named 'ì¹œì ˆí•œ ì œì£¼Â°C' specializing in recommending restaurants in Jeju Island based on specific data.
Use the provided data to answer accurately. If unsure, respond that you don't know.

- When the user's question is a general recommendation request, follow the structured format below.
- If the user's question is asking for a specific piece of information (e.g., "What is the local visitation rate for ê³µëª…ì‹ë‹¹?"), provide only the requested information without additional formatting or explanation.
- If the user's question is about statistical data (e.g., "What is the highest local visitation rate for Chinese restaurants in the southern region?"), provide the specific statistical value directly and clearly.

Always base your answer strictly on the given data context.

When making recommendations, consider the user's visiting day, age group, and preferred time slot, recommending 1-3 places at most.
You have to start with a summary of the relevant temperature information from the retrieved context for {visit_month} and {visit_times}, and then continue with restaurant recommendations.

The following columns are relevant for finding the best recommendations:
- Weekday column: {weekdays_col}
- Time slot column: {time_col}
- Age group column: {age_col}

User's information:
- user's name: {user_name}
- user's age: {user_age}


Structured Format for general recommendations:
"**{{user_name}}**ë‹˜! {{visit_month}} {{visit_times}}ì— {{visit_region}} ì§€ì—­ì—ì„œ ì¸ê¸° ìˆëŠ” ë§›ì§‘ì„ ì¶”ì²œë“œë¦¬ê² ìŠµë‹ˆë‹¤! \n
ğŸŒ¡ï¸{{visit_month}} {{visit_times}}ì˜ {{visit_region}}ì˜ í‰ê·  ê¸°ì˜¨ì€ **{{average_temperature}}**ì…ë‹ˆë‹¤. ì—¬í–‰ì— ì°¸ê³ í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤. \n

**{{ê°€ë§¹ì ëª…}}**:
- ğŸ ì£¼ì†Œ: {{ì£¼ì†Œ}}
- ğŸ“Š{visit_month} {{visit_region}} ì§€ì—­ì—ì„œ {user_age}ì˜ ë°©ë¬¸ ë¹„ìœ¨ì´ {{value of age_col}}%ë¡œ {user_name}ë‹˜ê³¼ ë¹„ìŠ·í•œ ì—°ë ¹ëŒ€ì˜ ê³ ê°ì´ ë§ì´ ì°¾ì•˜ìŠµë‹ˆë‹¤.
- âœ…{user_name}ë‹˜ì´ ë°©ë¬¸í•˜ì‹œë ¤ëŠ” **{{weekdays_col}}**ì—ëŠ” ë°©ë¬¸ ë¹„ì¤‘ì´ {{value of weekday_col}}%ì…ë‹ˆë‹¤.
- âœ…{visit_times}ì˜ ì´ìš© ê±´ìˆ˜ ë¹„ì¤‘ì€ {time_col}% ìœ¼ë¡œ ë†’ì€/ë‚®ì€ í¸ì…ë‹ˆë‹¤.
- âœ…ì´ ë§›ì§‘ì˜ ì›”ë³„ ì—…ì¢…ë³„ ì´ìš©ê±´ìˆ˜ ë¶„ìœ„ìˆ˜ êµ¬ê°„ì€ {{ì›”ë³„ ì—…ì¢…ë³„ ì´ìš©ê±´ìˆ˜ ë¹„ì¤‘}}ì— ì†í•˜ë©°, ì›”ë³„ ì—…ì¢…ë³„ ì´ìš©ê¸ˆì•¡ ë¶„ìœ„ìˆ˜ êµ¬ê°„ì€ {{ì›”ë³„ ì—…ì¢…ë³„ ì´ìš©ê¸ˆì•¡ ë¶„ìœ„ìˆ˜ êµ¬ê°„}}ì…ë‹ˆë‹¤. ë°©ë¬¸í•˜ì‹œê¸° ì „ì— ì°¸ê³ í•˜ì„¸ìš”!
- ğŸšì£¼ë³€ ê´€ê´‘ì§€: ë§›ì§‘ê³¼ ê°€ê¹Œìš´ ê³³ì— **{{ë§›ì§‘ ì£¼ë³€ ê´€ê´‘ì§€}}**ì´(ê°€) ìˆìŠµë‹ˆë‹¤.

ì¦ê±°ìš´ ì‹ì‚¬ ë˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤!"

**For Specific Data Requests:**
- If the user's question is asking for specific data (e.g., "What is the local visitation rate for ê³µëª…ì‹ë‹¹?"), provide only the requested information in a simple and polite format with the specific value without Structured Format for general recommendations.

**For Comparison Requests:**
- If the user's question involves a comparison (e.g., "between these two, which restaurant has a higher local visitation rate?"), provide only the comparison result in polite way and relevant values without Structured Format for general recommendations.
- Example Answer: "ê³µëª…ì‹ë‹¹ì˜ í˜„ì§€ì¸ ë°©ë¬¸ ë¹„ì¤‘ì€ 34.3%ì´ê³ , ë‚˜ë˜ì‹ë‹¹ì˜ í˜„ì§€ì¸ ë°©ë¬¸ ë¹„ì¤‘ì€ 50.4%ì…ë‹ˆë‹¤. ë‚˜ë˜ì‹ë‹¹ì´ ë” ë†’ìŠµë‹ˆë‹¤."

**For Statistical Data Requests:**
- If the user's question is about statistical analysis (e.g., "What is the average local visitation rate for Chinese restaurants in the southern region?"), provide the specific statistical value politely without Structured Format for general recommendations.
  Example Answer:"ë‚¨ë¶€ ì¤‘ì‹ ë§›ì§‘ì˜ í‰ê·  í˜„ì§€ì¸ ë°©ë¬¸ ë¹„ì¤‘ì€ 54.2% ì…ë‹ˆë‹¤."

**For Region-Restricted Requests:**
- If the user's query is about a restaurant or place in a region outside the selected {{visit_region}}, respond with: "(e.g.) ì •ë³´ë¥¼ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì˜ ë°©ë¬¸ ì§€ì—­ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”."

Use the provided context and user information strictly:
[context]: {context}
[previous_chat_history]: {previous_chat_history}
---
[ì§ˆë¬¸]: {query}
"""
prompt = ChatPromptTemplate.from_template(template)


### 7. Google Gemini ëª¨ë¸ ìƒì„± ###
system_instruction = """ë‹¹ì‹ ì€ ì œì£¼ë„ ì—¬í–‰ê°ì—ê²Œ ë§›ì§‘ì„ ì¶”ì²œí•˜ëŠ” 'ì¹œì ˆí•œ ì œì£¼Â°C' ì±—ë´‡ì…ë‹ˆë‹¤. 
ê° ëŒ€í™”ì—ì„œ í•„ìš”í•œ ì •ë³´ë¥¼ ì •í™•íˆ ì œê³µí•˜ê³ , ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ í›„ì† ì§ˆë¬¸ì¸ ê²½ìš° ì´ì „ ëŒ€í™”ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
í•„ìš”í•œ ê²½ìš° ê°„ê²°í•˜ê²Œ ì •ë³´ë¥¼ ì œê³µí•˜ê³ , ëŒ€í™”ì˜ ë§¥ë½ì„ ìœ ì§€í•˜ì—¬ ì§ˆë¬¸ê³¼ ê´€ê³„ ì—†ëŠ” ì •ë³´ë¥¼ ìƒëµí•˜ì„¸ìš”.
"""
llm = load_model.load_gemini(system_instruction)


### 8. ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§ & ë³‘í•© í•¨ìˆ˜ ###
# visit_region ë°ì´í„° í•„í„°ë§
def filter_restaurant_docs(docs, visit_region):
    return [doc for doc in docs if doc.metadata.get('ì§€ì—­') in visit_region]

# ê¸°ì˜¨ ë°ì´í„°ëŠ” ê¸°ì¤€ë…„ì›” + ì§€ì—­ìœ¼ë¡œ í•„í„°ë§
def filter_temperature_docs(docs, visit_region, visit_month):
    return [
        doc for doc in docs 
        if doc.metadata.get('ì§€ì—­') in visit_region and doc.metadata.get('ê¸°ì¤€ë…„ì›”') == visit_month
    ]

def format_docs(docs):
  return "\n\n".join(doc.page_content for doc in docs)

def retrieve_and_filter_context(_input):
    # ë§›ì§‘ ë°ì´í„°ì™€ ê¸°ì˜¨ ë°ì´í„°ì—ì„œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
    temp_docs = temp_retriever.invoke(_input)
    main_docs = retriever.invoke(_input)

    # temp_retrieverì™€ retriever ê°ê° í•„í„°ë§ í•¨ìˆ˜ ì ìš© í›„ ë³‘í•©
    filtered_main_docs = filter_restaurant_docs(main_docs, visit_region)
    filtered_temp_docs = filter_temperature_docs(temp_docs, visit_region, visit_month)

    # í•„í„°ë§ëœ ê²°ê³¼ê°€ ì—†ë‹¤ë©´ ì˜¤ë¥˜ ë©”ì‹œì§€ ë°˜í™˜
    if not filtered_temp_docs and not filtered_main_docs:
        return "ë§ì”€í•˜ì‹  ì§€ì—­ì— ëŒ€í•œ ë§›ì§‘ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ë°©ë¬¸í•˜ì‹¤ ì§€ì—­ì„ ë‹¤ì‹œ ì„ íƒí•´ì£¼ì„¸ìš”."
    # ë³‘í•© í›„ í˜•ì‹í™”
    return format_docs(filtered_temp_docs + filtered_main_docs)

## 9. LangChain ì²´ì¸ êµ¬ì„± ###
rag_chain = (
  {"query":RunnablePassthrough(),
    "context": retrieve_and_filter_context,
    "previous_chat_history":RunnablePassthrough(),
    "user_name":RunnablePassthrough(),
    "user_age":RunnablePassthrough(),
    "visit_times":RunnablePassthrough(),
    "visit_month":RunnablePassthrough(),
    "visit_region":RunnablePassthrough(),
    "age_col":RunnablePassthrough(),
    "weekdays_col":RunnablePassthrough(),
    "time_col":RunnablePassthrough(),
  }
  # question(ì‚¬ìš©ìì˜ ì§ˆë¬¸) ê¸°ë°˜ìœ¼ë¡œ ì—°ê´€ì„±ì´ ë†’ì€ ë¬¸ì„œ retriever ìˆ˜í–‰ >> format_docsë¡œ ë¬¸ì„œë¥¼ í•˜ë‚˜ë¡œ ë§Œë“¦
  | prompt               # í•˜ë‚˜ë¡œ ë§Œë“  ë¬¸ì„œë¥¼ promptì— ë„˜ê²¨ì£¼ê³ 
  | llm                  # llmì´ ì›í•˜ëŠ” ë‹µë³€ì„ ë§Œë“¦
  | StrOutputParser()
)


### 10. Streamlit UI ###
st.subheader("ğŸŠ:orange[ì œì£¼Â°C]ì—ê²Œ ì§ˆë¬¸í•˜ê¸°")
st.caption("ğŸš€ 2024 ë¹…ì½˜í…ŒìŠ¤íŠ¸ (ìƒì„±í˜• AI ë¶„ì•¼) íŒ€: í—¬ë¡œë¹…ì½˜")
st.divider()

say_hi_to_user = f"""ì•ˆë…•í•˜ì„¸ìš”! ğŸŠ ì œì£¼ë„ ë§›ì§‘ ì¶”ì²œ AI :orange[**ì¹œì ˆí•œ ì œì£¼Â°C**]ì…ë‹ˆë‹¤.  
ì €ëŠ” ì œì£¼ë„ì˜ ì§€ì—­ë³„, ì‹œê°„ëŒ€ë³„ í‰ê·  ê¸°ì˜¨ ë°ì´í„°ì™€ í•¨ê»˜ ì‚¬ìš©ì ë§ì¶¤í˜• ë§›ì§‘ì„ ì¶”ì²œí•´ë“œë ¤ìš”! \n\n
ì‚¬ì „ì— ì…ë ¥í•˜ì‹  :rainbow[**{user_name}**]ë‹˜ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë”ìš± ì •í™•í•œ ì¶”ì²œì„ í•´ë“œë¦½ë‹ˆë‹¤.  
"**ì¶”ìë„ì— ìˆëŠ” ê°€ì •ì‹ ë§›ì§‘ì„ ì¶”ì²œë°›ê³  ì‹¶ë‹¤**"ê±°ë‚˜ "**ì¶”ì²œë°›ì€ ë‘ ì‹ë‹¹ì˜ í˜„ì§€ì¸ ë°©ë¬¸ ë¹„ì¤‘ì„ ë¹„êµí•˜ê³  ì‹¶ë‹¤**"ë©´, ì €ì—ê²Œ ì–¸ì œë“ ì§€ ì§ˆë¬¸í•´ì£¼ì„¸ìš”! \n\n
**âœˆï¸ ì œì£¼ ì—¬í–‰ì„ ë” ì¦ê²ê³  ë§›ìˆê²Œ ë§Œë“¤ì–´ë“œë¦´ê²Œìš”!**  
"""

user_input = st.chat_input(
    placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: ì¶”ìë„ì— ìˆëŠ” ê°€ì •ì‹ ë§›ì§‘ì„ ì¶”ì²œí•´ì¤˜)",
    max_chars=150,
)

chat_col1, search_col2 = st.columns([2, 1])
with search_col2:
    chat_search.show_search_restaurant()

    # ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
    if st.button("ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”", type='primary'):
        st.session_state.messages = [
            {"role": "assistant", "content": say_hi_to_user}
        ]
        st.rerun()

with chat_col1:
    if 'messages' not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": say_hi_to_user}
        ]
    # í•„ìˆ˜ ì •ë³´ê°€ ì…ë ¥ë˜ì§€ ì•Šì•˜ì„ ê²½ìš° ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶œë ¥
    if not (user_age and visit_dates and visit_times and visit_region):
        st.error("ì‚¬ìš©ì ì •ë³´(ì—°ë ¹ëŒ€, ë°©ë¬¸ ë‚ ì§œ, ì‹œê°„, ì§€ì—­)ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. \nì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.", icon=":material/error:")
        st.stop()  # ì´í›„ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì§€ ì•Šë„ë¡ ì¤‘ë‹¨


    for message in st.session_state.messages:
        avatar = "ğŸ§‘ğŸ»" if message['role'] == 'user' else botImgPath
        with st.chat_message(message['role'], avatar=avatar):
            st.markdown(message['content'])

    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user", avatar="ğŸ§‘ğŸ»"):
            st.markdown(user_input)

        # ëŒ€í™” ê¸°ë¡ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        previous_chat_history = "\n".join([f"{msg['role']}: {msg['content']}" for msg in st.session_state.messages])

        # ì¶”ì²œ ìƒì„± ì¤‘ ìŠ¤í”¼ë„ˆ
        with st.spinner("ë§›ì§‘ ì°¾ëŠ” ì¤‘..."):
            query_text = (
                f"ì§ˆë¬¸: {user_input}\n\n\n"
                "User's Information: "
                f"user_name: {user_name}\n"
                f"user_age: {user_age}\n"
                f"visit_region: {visit_region}\n"
                f"visit_month: {visit_month}\n"
                f"visit_times: {visit_times}\n"
                f"previous_chat_histroy:{previous_chat_history}"
            )
            # chain.invokeì—ì„œ ê°œë³„ ë³€ìˆ˜ë¡œ ì „ë‹¬
            assistant_response = rag_chain.invoke(query_text)
        # Assistant ì‘ë‹µ ê¸°ë¡ì— ì¶”ê°€ ë° ì¶œë ¥
        st.session_state.messages.append({"role": "assistant", "content": assistant_response})
        with st.chat_message("assistant", avatar=botImgPath):
            st.markdown(assistant_response)  
